# üöÄ Performance Optimization Guide - ‡πÅ‡∏ä‡∏ó 100 ‡∏Ñ‡∏ô‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô

## ‚ö†Ô∏è ‡∏™‡∏£‡∏∏‡∏õ‡∏õ‡∏±‡∏ç‡∏´‡∏≤

**Current Status:** ‚ö†Ô∏è **‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö 100 ‡∏Ñ‡∏ô‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô**

**Bottleneck ‡∏´‡∏•‡∏±‡∏Å:**
1. üî¥ **Database Connection Pool:** `connectionLimit: 10` ‚Üí ‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö 100 requests
2. üü° **Multiple Queries per Message:** 2-3 queries per message
3. üü° **Socket.IO fetchSockets():** Overhead ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏°‡∏µ sockets ‡∏°‡∏≤‡∏Å

---

## ‚úÖ Quick Fixes (‡∏ó‡∏≥‡πÑ‡∏î‡πâ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ)

### 1. **‡πÄ‡∏û‡∏¥‡πà‡∏° Database Connection Pool** üî¥ **Priority: Critical**

**File:** `server/utils/db.ts`

```typescript
// ‚ùå ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
connectionLimit: 10

// ‚úÖ ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÄ‡∏õ‡πá‡∏ô
connectionLimit: 50, // ‡∏´‡∏£‡∏∑‡∏≠‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤
```

**‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:**
- ‚úÖ ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö concurrent requests ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô 5 ‡πÄ‡∏ó‡πà‡∏≤
- ‚úÖ ‡∏•‡∏î connection timeout errors

---

### 2. **‡∏•‡∏î fetchSockets() Calls** üü° **Priority: High**

**File:** `server/api/chat/rooms/[roomId]/messages.post.ts`

```typescript
// ‚ùå ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô - fetch sockets ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á
const roomSockets = await io.in(`room:${roomId}`).fetchSockets()
console.log(`[API] üîç Room ${roomId} has ${roomSockets.length} connected socket(s)`)

// ‚úÖ ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç - emit ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á (‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á fetch)
// ‡∏•‡∏ö fetchSockets() ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á log
io.to(`room:${roomId}`).emit('new_message', message)
```

**‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:**
- ‚úÖ ‡∏•‡∏î CPU overhead
- ‚úÖ ‡∏•‡∏î latency

---

### 3. **Cache Room Info** üü° **Priority: Medium**

**File:** `server/api/chat/rooms/[roomId]/messages.post.ts`

```typescript
// ‡πÄ‡∏û‡∏¥‡πà‡∏° simple cache
const roomCache = new Map<number, { room: ChatRoom, expires: number }>()

// ‡πÉ‡∏ô messages.post.ts
const getCachedRoom = async (roomId: number) => {
  const cached = roomCache.get(roomId)
  if (cached && cached.expires > Date.now()) {
    return cached.room
  }
  
  const room = await getChatRoom(roomId)
  roomCache.set(roomId, {
    room,
    expires: Date.now() + 60000 // Cache 1 ‡∏ô‡∏≤‡∏ó‡∏µ
  })
  return room
}
```

**‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:**
- ‚úÖ ‡∏•‡∏î database queries
- ‚úÖ ‡∏•‡∏î latency

---

## üîß Advanced Optimizations

### 1. **Message Queue (Redis/Bull)** üü° **Priority: Medium**

**Install:**
```bash
npm install bull ioredis
```

**Setup:**
```typescript
// server/utils/queue.ts
import Queue from 'bull'
import Redis from 'ioredis'

const redis = new Redis({
  host: process.env.REDIS_HOST || 'localhost',
  port: parseInt(process.env.REDIS_PORT || '6379')
})

export const messageQueue = new Queue('messages', {
  redis: {
    host: process.env.REDIS_HOST || 'localhost',
    port: parseInt(process.env.REDIS_PORT || '6379')
  },
  defaultJobOptions: {
    attempts: 3,
    backoff: {
      type: 'exponential',
      delay: 2000
    }
  }
})

// Worker
messageQueue.process('send', 10, async (job) => {
  const { roomId, message, userId } = job.data
  
  // Save to database
  const savedMessage = await saveMessage(message)
  
  // Emit via Socket.IO
  const io = (useNitroApp() as any).io
  if (io) {
    io.to(`room:${roomId}`).emit('new_message', savedMessage)
  }
  
  return savedMessage
})
```

**Usage:**
```typescript
// ‡πÉ‡∏ô messages.post.ts
await messageQueue.add('send', {
  roomId,
  message: {
    room_id: roomId,
    sender_id: auth.userId,
    // ...
  },
  userId: auth.userId
})

// Return immediately
return { success: true, queued: true }
```

**‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:**
- ‚úÖ API response ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ
- ‚úÖ Database writes ‡πÄ‡∏õ‡πá‡∏ô background
- ‚úÖ Better error handling

---

### 2. **Batch Database Operations** üü° **Priority: Medium**

**File:** `server/services/chat.service.ts`

```typescript
// ‡πÄ‡∏û‡∏¥‡πà‡∏° batch insert function
export async function batchSaveMessages(
  messages: Array<{
    room_id: number
    sender_id: number
    content: string | null
    message_type: 'text' | 'image' | 'file' | 'system'
    // ...
  }>
): Promise<ChatMessage[]> {
  if (messages.length === 0) return []
  
  // Build batch INSERT
  const values = messages.map(() => '(?, ?, ?, ?, ?, ?, ?, ?, FALSE)').join(', ')
  const params = messages.flatMap(m => [
    m.room_id,
    m.sender_id,
    m.message_type,
    m.content,
    m.file_url || null,
    m.file_name || null,
    m.file_size || null,
    m.file_type || null
  ])
  
  await execute(
    `INSERT INTO chat_messages 
     (room_id, sender_id, message_type, content, file_url, file_name, file_size, file_type, is_read)
     VALUES ${values}`,
    params
  )
  
  // Return saved messages
  // ...
}
```

**‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:**
- ‚úÖ ‡∏•‡∏î database round trips
- ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏° throughput

---

### 3. **Socket.IO Redis Adapter** üü¢ **Priority: Low**

**Install:**
```bash
npm install @socket.io/redis-adapter
```

**Setup:**
```typescript
// server/plugins/socket.io.ts
import { createAdapter } from '@socket.io/redis-adapter'
import { createClient } from 'redis'

const pubClient = createClient({ url: 'redis://localhost:6379' })
const subClient = pubClient.duplicate()

await Promise.all([pubClient.connect(), subClient.connect()])

io.adapter(createAdapter(pubClient, subClient))
```

**‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:**
- ‚úÖ ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö multiple server instances
- ‚úÖ Load balancing

---

## üìä Performance Comparison

### **Before Optimization:**
```
100 concurrent messages:
- Connection pool: 10 ‚Üí 90 requests wait
- Database writes: 10-50 seconds
- Socket.IO emits: 100-500ms
- Total: 10-50 seconds ‚ö†Ô∏è
```

### **After Quick Fixes:**
```
100 concurrent messages:
- Connection pool: 50 ‚Üí 50 requests wait
- Database writes: 2-10 seconds
- Socket.IO emits: 50-200ms
- Total: 2-10 seconds üü°
```

### **After Advanced Optimizations:**
```
100 concurrent messages:
- Message queue: Immediate response
- Database writes: Background (1-3 seconds)
- Socket.IO emits: 50-200ms
- Total: <1 second ‚úÖ
```

---

## üéØ Implementation Priority

### **Phase 1: Quick Fixes (1-2 hours)**
1. ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏° connection pool ‡πÄ‡∏õ‡πá‡∏ô 50
2. ‚úÖ ‡∏•‡∏î fetchSockets() calls
3. ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏° room cache

**Expected improvement:** 50-70% faster

### **Phase 2: Message Queue (4-8 hours)**
1. ‚úÖ Setup Redis
2. ‚úÖ Setup Bull queue
3. ‚úÖ Migrate message sending to queue

**Expected improvement:** 80-90% faster

### **Phase 3: Advanced (1-2 days)**
1. ‚úÖ Batch operations
2. ‚úÖ Redis adapter
3. ‚úÖ Load balancing

**Expected improvement:** 95%+ faster

---

## üß™ Testing

### **Load Test Script:**
```typescript
// scripts/load-test-chat.ts
import axios from 'axios'

const API_URL = 'http://localhost:4000/api'
const TOKEN = 'your-test-token'
const ROOM_ID = 1

async function sendMessage(userId: number) {
  try {
    const start = Date.now()
    await axios.post(
      `${API_URL}/chat/rooms/${ROOM_ID}/messages`,
      {
        content: `Test message from user ${userId}`,
        message_type: 'text'
      },
      {
        headers: {
          Authorization: `Bearer ${TOKEN}`
        }
      }
    )
    const duration = Date.now() - start
    console.log(`User ${userId}: ${duration}ms`)
    return duration
  } catch (error) {
    console.error(`User ${userId} failed:`, error.message)
    return -1
  }
}

async function loadTest() {
  const users = 100
  const promises = Array.from({ length: users }, (_, i) => sendMessage(i + 1))
  const results = await Promise.all(promises)
  
  const successful = results.filter(r => r > 0)
  const avgTime = successful.reduce((a, b) => a + b, 0) / successful.length
  const maxTime = Math.max(...successful)
  const minTime = Math.min(...successful)
  
  console.log(`\nResults:`)
  console.log(`Total: ${users}`)
  console.log(`Successful: ${successful.length}`)
  console.log(`Failed: ${users - successful.length}`)
  console.log(`Avg time: ${avgTime.toFixed(2)}ms`)
  console.log(`Max time: ${maxTime}ms`)
  console.log(`Min time: ${minTime}ms`)
}

loadTest()
```

---

## üìà Monitoring

### **Key Metrics:**
- Database connection pool usage
- Socket.IO connection count
- Message queue length
- Response times (p50, p95, p99)
- Error rates

### **Tools:**
- PM2 monitoring
- New Relic / Datadog
- Custom metrics endpoint

---

## ‚úÖ Conclusion

**Current:** ‚ö†Ô∏è **‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö 100 ‡∏Ñ‡∏ô‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô** (connection pool 10)

**After Quick Fixes:** üü° **‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô** (connection pool 50)

**After Full Optimization:** ‚úÖ **‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ‡πÄ‡∏ï‡πá‡∏°‡∏ó‡∏µ‡πà** (message queue + optimizations)

